[
  {
    "instruction": "Demonstrate how `jax.jit` can be used to optimize a recursive function in JAX. Write a recursive function to compute the nth Fibonacci number and compare its performance with and without JIT compilation.",
    "solution_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\nimport time\n\n# Define a recursive Fibonacci function\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\n# Define a JIT-compiled Fibonacci function\n@jit\ndef fibonacci_jit(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci_jit(n-1) + fibonacci_jit(n-2)\n\n# Example usage and timing (demonstration purposes - timing can vary)\nn = 30\n\n# Time the un-JITted version\nstart_time = time.time()\nuncompiled_result = fibonacci(n)\nuncompiled_time = time.time() - start_time\n\n# Time the JITted version\nstart_time = time.time()\ncompiled_result = fibonacci_jit(n)\ncompiled_time = time.time() - start_time\n\nprint(f\"Uncompiled Fibonacci({n}) = {uncompiled_result}, Time: {uncompiled_time:.4f} seconds\")\nprint(f\"JIT Compiled Fibonacci({n}) = {compiled_result}, Time: {compiled_time:.4f} seconds\")\n\n# Note:  The first execution of the JITted function will include compilation time.\n# Subsequent calls will be much faster.\n\n# Force JIT compilation to complete before timing\nfibonacci_jit(1).block_until_ready()\n\nstart_time = time.time()\ncompiled_result = fibonacci_jit(n)\ncompiled_time = time.time() - start_time\n\n\nprint(f\"JIT Compiled Fibonacci({n}) = {compiled_result}, Time: {compiled_time:.4f} seconds (after initial compilation)\")",
    "test_cases": [
      {
        "setup_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef fibonacci_jit(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci_jit(n-1) + fibonacci_jit(n-2)\n\n\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\n\nn = 10",
        "assertion": "assert fibonacci_jit(n) == fibonacci(n)"
      },
      {
        "setup_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef fibonacci_jit(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci_jit(n-1) + fibonacci_jit(n-2)\n\n\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\n\nn = 5",
        "assertion": "assert fibonacci_jit(n) == 5"
      },
      {
        "setup_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef fibonacci_jit(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci_jit(n-1) + fibonacci_jit(n-2)\n\n\nn = 0",
        "assertion": "assert fibonacci_jit(n) == 0"
      }
    ]
  },
  {
    "instruction": "Explain the concept of 'compilation cache' in JAX and how it affects the performance of JIT compiled functions. Provide a code example to show how the compilation cache works.",
    "solution_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\nimport time\n\n# JAX's compilation cache stores compiled versions of JIT-decorated functions.\n# When a JIT-decorated function is called for the first time with specific argument shapes and dtypes,\n# JAX compiles it into optimized machine code using XLA. This compilation process can be slow.\n\n# Subsequent calls to the same function with the same argument shapes and dtypes\n# will reuse the cached compiled code, avoiding recompilation and significantly improving performance.\n\n# Changing the shapes or dtypes of the arguments will trigger recompilation, as it may require a different optimization strategy.\n\n# Example:\n\n@jit\ndef my_function(x):\n  return jnp.sin(x) + jnp.cos(x)\n\n# First call: compilation happens\nstart_time = time.time()\nresult1 = my_function(jnp.array([1.0, 2.0, 3.0]))\nend_time = time.time()\ncompilation_time = end_time - start_time\nprint(f\"Compilation time (first call): {compilation_time:.4f} seconds\")\n\n# Second call: uses the cached compiled code\nstart_time = time.time()\nresult2 = my_function(jnp.array([4.0, 5.0, 6.0]))\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(f\"Execution time (second call): {execution_time:.4f} seconds\")\n\n# Third call with different dtype: recompilation happens because the cache key is different.\nstart_time = time.time()\nresult3 = my_function(jnp.array([4, 5, 6])) # integer array\nend_time = time.time()\nrecompilation_time = end_time - start_time\nprint(f\"Recompilation time (third call with different dtype): {recompilation_time:.4f} seconds\")",
    "test_cases": [
      {
        "setup_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef add_one(x):\n    return x + 1\n\nkey = jax.random.PRNGKey(0)\nx = jax.random.normal(key, (10,))",
        "assertion": "assert jnp.allclose(add_one(x), x + 1)"
      },
      {
        "setup_code": "import jax\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef multiply_by_two(x):\n    return x * 2\n\ny = jnp.array([1, 2, 3, 4, 5])",
        "assertion": "assert jnp.allclose(multiply_by_two(y), y * 2)"
      }
    ]
  }
]